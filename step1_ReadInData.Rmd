---
title: "Read in Initial Data"
output: html_document
date: "2024-08-17"
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

```


***WARNING:*** You MUST run this script from top to bottom.  Running only part of it will result in errors.  Data frames are named the same thing at the begining of the script as the end.  This improves performance in large data sets, but means that great care should be taken when the script is not run from top to bottom.

***FIRST*** Be sure to set up your farm name and state name on lines 45 and 46 if you are not going to customize the functions to set these.

***NEXT*** Pull events from dairy comp using this code:

Option 1 Pull 5 years in one file: EVENTS\2S2000C #1 #2 #4 #5 #6 #11 #12 #13 #15 #28 #29 #30 #31 #32 #38 #40 #43

Option 2 pull smaller time frames using "days back" starting with "S""days back" and ending with "L""days back":  EVENTS\2S99L0C #1 #2 #4 #5 #6 #11 #12 #13 #15 #28 #29 #30 #31 #32 #38 #40 #43


This code pulls the following items along with the columns always generated with an events2 command in DC305:

"ID" "PEN" "REG" "EID" "CBRD" "BDAT" "EDAT" "LACT" "RC" "HDAT" "FDAT" "CDAT" "DDAT" "PODAT" "ABDAT" "VDAT"   "ARDAT" 

"Event" "DIM" "Date" "Remark" "Protocols" "R" "T" "B"  "Technician"

***THEN*** Place your files in this folder "Data/EventFiles"

The code in chunk 3 will read in all files in this folder so do not leave old files here that you do not want to process.

***FINALLY*** Turn on/off (comment/un-comment) lines 128 and 131 to use custom functions for event types and source farm/state


```{r}
library(tidyverse)
library(gt)

#custom functions, turn off or on  on line 124 and 126
source('FUNCTIONS/fxn_sourcefarms.R') #custom function that parses cow id to identify source farm, it is farm specific
source('FUNCTIONS/fxn_event_type.R') #custom function to identify source state based on farm

set_farm_name<-'Example Farm Name'
set_farm_state<-'Example Farm State'




```


```{r read in files}

list_files<-list.files('Data/EventFiles') #folder name where event files are located

events<-NULL

for (i in seq_along(list_files)){
  df<-read_csv(paste0('Data/EventFiles/', 
                      list_files[i]), 
               #reads in all data as character string
               col_types = cols(.default = 'c'))%>% 
    mutate(Remark = str_replace_all(Remark, "[^[:alnum:]]", "_")) #gets rid of weird characters that mess up encoding or parsing
    
  events<-bind_rows(events, df)
}


```


```{r initial cleanup}
events2<-events%>%
  #take out junk------------------
  filter(!(is.na(Date)))%>% #get rid of columns that are missing a date - they are not useful
  filter(!(is.na(Event)))%>% #get rid of columns that do not have an event - they are also not useful
  select(-starts_with('...'))%>% #get rid of extra columns created by odd parsing in the csv file
  #create unique cow id--------------------------------------- 
  mutate(animal_id = paste0(ID, '_', BDAT), 
         animal_id_lact = paste0(ID, '_', BDAT, '_', LACT), 
         breed = CBRD)%>%
  #format date--------------------------------------- 
  mutate(date = lubridate::mdy(Date), 
         
          bdat = lubridate::mdy(BDAT), 
         
         fdat = lubridate::mdy(FDAT), 
         ardat = lubridate::mdy(ARDAT),
        
         
         cdat = lubridate::mdy(CDAT), 
         abdat = lubridate::mdy(ABDAT),
         ddat = lubridate::mdy(DDAT),
         edat = lubridate::mdy(EDAT), 
         hdat = lubridate::mdy(HDAT),
         podat = lubridate::mdy(PODAT)
         
         )%>%
  #parse numbers -------------------
  mutate(DIM = parse_number(DIM), 
         LACT = parse_number(LACT))%>%
  arrange(animal_id, date)%>%
  distinct()%>%
  #replace missing values in remark and protocols to allow grouping later----------------
  mutate(Protocols = str_replace_na(Protocols, 'BLANK_UNKNOWN'), 
         Remark = str_replace_na(Remark, 'BLANK_UNKNOWN'))%>%
  #add standard event types-----------------
  fxn_event_type_default()%>%
  #add default source farm info-----------------
  fxn_add_source_farm_default()

```


```{r generate event_type template}
#create event type template---------------------
  template_event_type <- events2%>%
    group_by(Event, Protocols, event_type)%>%
    summarize(count = sum(n()))%>%
    ungroup()
  write_csv(template_event_type, 'Data/TemplateFiles/template_event_type.csv')
  
```

```{r farm custom variables}
#define event types------------------------------------
  events2 <-events2%>%
  
  #standardize event type--------------------
  #fxn_event_type_custom()%>% # turn this off or on, you must modify this function in the function file
  
  #add source farm ------------------
  #fxn_add_source_farm_custom() %>% # turn this off or on, you must modify this function in the function file
  
  #fix na values-------------
  mutate(
    event_type = case_when(
      is.na(event_type)~'Unknown',
      TRUE~event_type), 
    source_farm = case_when(
      is.na(source_farm)~'Unknown', 
      TRUE~source_farm), 
    source_state = case_when(
      is.na(source_state)~'Unknown', 
      TRUE~source_state),
    breed = case_when(
      is.na(breed)~'Unknown', 
      TRUE~breed)
  )%>%
  mutate(
    LACTgroup_basic = case_when(
      (LACT == 0)~'Heifer', 
      (LACT >0)~'LACT > 0',
      TRUE~'Unknown'), 
    LACTgroup_repro = case_when(
      (LACT == 0)~'Heifer', 
      (LACT ==1)~'LACT 1',
      (LACT >1)~'LACT 2+',
      TRUE~'Unknown'),
    LACTgroup = case_when(
      (LACT == 0)~'Heifer', 
      (LACT ==1)~'LACT 1',
      (LACT ==2)~'LACT 2',
      (LACT >2)~'LACT 3+',
      TRUE~'Unknown')
    )


```


```{r write out files}

#main file------------
write_rds(events2, 'Data/IntermediateFiles/events2.rds')

#data quality files------------
QC_event_type<-events2%>%
  filter(event_type %in% 'Unknown')%>%
  group_by(Event, Protocols, event_type)%>%
  summarize(count = sum(n()))%>%
  ungroup()
write_rds(QC_event_type, 'Data/QCFiles/QC_event_type.rds')


QC_source_farm<-events2%>%
  filter(source_farm %in% 'Unknown')%>%
  group_by(Event, Protocols, source_farm)%>%
  summarize(count = sum(n()))%>%
  ungroup()
write_rds(QC_source_farm, 'Data/QCFiles/QC_source_farm.rds')

total_animals<-events2%>%
  mutate(year = year(date))%>%
  group_by(year, LACTgroup)%>%
  summarize(count_animals = n_distinct(animal_id), 
            count_lactations = n_distinct(animal_id_lact)
            )%>%
  ungroup()
              

```

## Initial Processing Report

#### Start date: `r min(events2$date)`

#### End date: `r max(events2$date)`

### Animal Counts

```{r}
total_animals%>%
  select(-count_lactations)%>%
  pivot_wider(names_from = 'LACTgroup', 
              values_from = 'count_animals')%>%
  gt()

ggplot(total_animals)+
  geom_bar(aes(x = year, y = count_animals), stat = 'identity')+
  facet_grid(.~LACTgroup)

```



### QC Event Types
Events not classified 

```{r}
if (dim(QC_event_type)[1]<1){
  print('All Event Types Mapped')
}else{
  ggplot(QC_event_type)+
    geom_bar(aes(x = Protocols, y = count), stat = 'identity', fill = 'red')+
    facet_wrap(Event~., scales = 'free_x')
}

summarize_event_type<-events2%>%
         group_by(event_type, LACTgroup)%>%
         summarize(count_animal_id = n_distinct(animal_id))%>%
         ungroup()

```

### QC Source Farms

```{r, fig.show="hold", out.width="50%"}

if (dim(QC_source_farm)[1]<1){
  print('All Source Farms Mapped')
}else{
  ggplot(QC_source_farm)+
    geom_bar(aes(x = Protocols, y = count), stat = 'identity', fill = 'red')+
    facet_wrap(Event~., scales = 'free')
}

summarize_source_farm<-events2%>%
         mutate(year = year(date))%>%
         group_by(source_farm, source_state, year)%>%
         summarize(count_animal_id = n_distinct(animal_id))%>%
         ungroup()

list_source_states<-sort(unique(events2$source_state))

#i=1
for (i in seq_along(list_source_states)){
p<-ggplot(summarize_source_farm%>%filter(source_state %in% list_source_states[i]))+ 
  geom_bar(aes(x = source_farm, y = count_animal_id, fill = factor(year)), 
           stat = 'identity', position = position_dodge(width = 0.8, preserve = "single"))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = paste0(list_source_states[i]), 
       fill = 'Year')+
  scale_fill_manual(values =c('#ffff99','#a6cee3','#b2df8a','#fb9a99','#fdbf6f','#cab2d6',
                              '#b15928', '#1f78b4','#33a02c','#e31a1c','#ff7f00','#6a3d9a'))
print(p)
}


```


### Main Data

```{r, fig.show="hold", out.width="50%"}
main_data<-events2%>%
  group_by(Event, event_type)%>%
  summarize(count_animal_id = n_distinct(animal_id))%>%
  ungroup()

list_event_types<-sort(unique(main_data$event_type))

#i=1
for (i in seq_along(list_event_types)){
p<-ggplot(main_data%>%filter(event_type %in% list_event_types[[i]]))+
  geom_bar(aes(x = Event, y = count_animal_id), stat = 'identity')+
  facet_wrap(event_type~., scales = 'free')+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = paste0(list_event_types[[i]]))

print(p)
}
  
```








